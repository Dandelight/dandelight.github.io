神经网络主要由两方面组成，一个**打分函数**输入数据映射到类分数，一个**损失函数**用于考量打分结果与真实结果的“距离”。之后的故事就是一个**优化问题**，即调节打分函数的参数，最小化损失函数的输出。

## 打分函数

假定我们有一个数据集$\{x_i | x_i \in R^D\}$，每张图片$x_i$对应一个标签$y_i$，$i=1\ldots N$，$y_i \in 1\ldots K$，$D$为输入图像的维度。打分函数$f: R^{D} \mapsto R^{K}$定义如下：

### 线性打分函数

最简单的打分函数莫过于线性函数
$$
f\left(x_{i}, W, b\right)=W x_{i}+b
$$
其中，$W \in R^{K\times D}$为权值，$b \in R^{K \times 1}$为偏置向量

线性打分函数输出一个$K\times 1$的向量，向量中每一个元素即为打分函数对该类别的打分。；![img](media/02/imagemap.jpg)

从数学上理解，线性分类器的之所以称为”线性“，是因为分类的原理是高维空间中的线性规划问题。以`CIFAR-10·`数据集为例，我们是在$32\times32\times3 = 3072$维空间中对点进行线性分类。

### Template Matching

从可视化结果来看，线性分类器学习到了一定的特征，虽然horse一类里的马好像有两个头……

![img](media/02/templates.jpg)

还有就是，一次卷积可以去掉加法，或者说，把加法融合到乘法里，充分利用了GPU，提高了数据并行性。

![img](media/02/wb.jpeg)

### 图像预处理

现在的数字图像一般都是RGB图像，每个图像的值在$[0, 255]$范围内。在神经网络中通常的做法是减去均值、除以方差，将输入特征规范化到$[-1, 1]$，这对神经网络的训练是有利的。

## 损失函数

损失函数的本意不复杂：惩罚错误。